{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification pipeline: Application with text data\n",
    "\n",
    "Author: Alexandre Gramfort\n",
    "\n",
    "The objective of this hands on session is to setup a predictive pipeline to classify movie critics. Critics are either positive (y=1) or negative (y=0). This task is often referred to as **sentiment analysis**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you are being given :\n",
    "\n",
    "- critics of movies in text files in folder *data/imdb1*,\n",
    "\n",
    "Your mission :\n",
    "\n",
    "- Extract numeric features (the 'X') from the raw data (word counts)\n",
    "- Apply a Logistic Regression classifier with proper setup of hyperparameter\n",
    "- Evaluate performance in terms of accuracy with cross-validation\n",
    "- Answer the question \"Do I have enough data?\" using a learning curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let's load the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "filenames_neg = sorted(glob(op.join('data', 'imdb1', 'neg', '*.txt')))\n",
    "filenames_pos = sorted(glob(op.join('data', 'imdb1', 'pos', '*.txt')))\n",
    "\n",
    "texts_neg = [open(f).read() for f in filenames_neg]\n",
    "texts_pos = [open(f).read() for f in filenames_pos]\n",
    "texts = texts_neg + texts_pos\n",
    "y = np.ones(len(texts), dtype=int)\n",
    "y[:len(texts_neg)] = 0.\n",
    "\n",
    "print(f\"{len(texts)} documents\")\n",
    "print(f\"Number of positives {len(texts_pos)} and negatives {len(texts_neg)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "- What does the array `y` correspond to?\n",
    "- What is the type of the variables `texts`?\n",
    "- Can you read the first text?\n",
    "- Complete the function **count_words** that counts the number of occurences of each word in a list of texts. You'll need to use the *split* method from the string class to split a text in words.\n",
    "\n",
    "Example of usage of the `split` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \"Hello DSSP attendees!\".split()\n",
    "print(words)\n",
    "print(\"number of words : %s\" % len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of usage of the `count_words` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">>> some_texts = ['A B B', 'B', 'A A']\n",
    ">>> vocabulary, counts = count_words(some_texts)\n",
    ">>> print(vocabulary)  # dictionary word -> column index\n",
    "{'A': 0, 'B': 1}\n",
    ">>> print(counts)  # number of occurence of each word from vocabulary in each text\n",
    "[[ 1.  2.]\n",
    " [ 0.  1.]\n",
    " [ 2.  0.]]\n",
    "```\n",
    "\n",
    "**Remark:** The vocabularty is a `dict` and its values have nothing to do with a number of occurences. Its values are the indices of columns in the `counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(texts):\n",
    "    \"\"\"Vectorize text : return count of each word in the text snippets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : list of str\n",
    "        The texts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vocabulary : dict\n",
    "        A dictionary that points to an index in counts for each word.\n",
    "    counts : ndarray, shape (n_samples, n_features)\n",
    "        The counts of each word in each text.\n",
    "        n_samples == number of documents.\n",
    "        n_features == number of words in vocabulary.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return vocabulary, counts\n",
    "\n",
    "vocabulary, counts = count_words(texts)\n",
    "print(counts.shape)\n",
    "print(counts.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Estimate Logistic regression on the full data. Show the effect of overfitting by evaluating the predictive power of your method in terms of accuracy.\n",
    "- Use the `train_test_split` function split the data in train and test (80% train and 20% test). What performance do you get?\n",
    "- Can you do better by adjusting the regularization parameter C? Use values between 0.00001 and 1000.\n",
    "- Why is this potentially dangerous? How do you avoid troubles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clf = LogisticRegression(C=1.)\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1., 10., 100., 1000.]\n",
    "\n",
    "for C in Cs:\n",
    "    # TODO\n",
    "\n",
    "print('Best C : %s - Best Score : %s' % (C_best, np.max(scores)))\n",
    "\n",
    "plt.plot(np.log10(Cs), scores)\n",
    "plt.xlabel(\"log10(C)\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Compare the performance of Logistic Regression vs Multinomial Nayes Bayes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Compare your implementation of word counting with scikit-learn.\n",
    "\n",
    "For this use the classes *CountVectorizer* and a *Pipeline*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score  # replace by cross_validation\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_df=0.75, ngram_range=(1, 1),\n",
    "                             analyzer='word', stop_words=None)),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, y, random_state=42)\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Could do you better with more data? Is the model complex too complex or too simple? Hint: Use a learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Can you do better using bigrams? Use parameter `ngram_range=(1, 2)` in CountVectorizer\n",
    "- Compare the learning curves using single words or bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_df=0.75, ngram_range=(1, 2),\n",
    "                             analyzer='word', stop_words=None)),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
